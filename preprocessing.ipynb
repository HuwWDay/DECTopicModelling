{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for getting writeups from the DEC website: https://dataethicsclub.com/write_ups/write-ups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'path', 'sha', 'size', 'url', 'html_url', 'git_url', 'download_url', 'type', '_links'])\n",
      "Number of writeup files:  69\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# GitHub API URL to fetch the contents of the specified directory\n",
    "api_url = 'https://api.github.com/repos/very-good-science/data-ethics-club/contents/site/write_ups'\n",
    "\n",
    "def get_md_files(api_url):\n",
    "    \"\"\"\n",
    "    Fetches the contents of the specified directory and returns a list of markdown files\n",
    "    \"\"\"\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        files = response.json()\n",
    "        md_files = [file for file in files if file['name'].endswith('.md')]\n",
    "        return md_files\n",
    "    else:\n",
    "        print(f\"Failed to fetch directory contents: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def read_md_file(file_url):\n",
    "    \"\"\"\n",
    "    Reads the contents of the specified markdown file\n",
    "    \"\"\"\n",
    "    response = requests.get(file_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Failed to fetch file content: {response.status_code}\")\n",
    "        return \"\"\n",
    "\n",
    "md_files = get_md_files(api_url)\n",
    "print(md_files[0].keys())\n",
    "print(\"Number of writeup files: \", len(md_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "doc_list = []\n",
    "\n",
    "for md_file in md_files:\n",
    "\n",
    "    # Read the content of the markdown files and add to a list\n",
    "\n",
    "\n",
    "    # Code to filter out only writeup files (not standalone blog posts, which have a slightly different format)\n",
    "    if 'writeup' not in md_file['name']:\n",
    "        continue\n",
    "    file_name = md_file['name']\n",
    "    file_date = file_name.split('_writeup')[0]\n",
    "    \n",
    "    file_url = md_file['download_url']\n",
    "    content = read_md_file(file_url)\n",
    "    doc_list.append(content)\n",
    "    #print(f\"Content of {md_file['name']}:\\n{content}\\n\")\n",
    "#print(len(doc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blogpost', 'date', 'author', 'category', 'tags', 'title', 'questions', 'content'])\n"
     ]
    }
   ],
   "source": [
    "def file_processor(md_file):\n",
    "    \"\"\"\n",
    "    Input a .md file as a string and return the metadata and content\n",
    "    metadata includes if an item is a blogpost, the date, the author, the category and the tags\n",
    "    Also get the title of the blogpost\n",
    "    And the questions of the blogpost\n",
    "    And finally the actual relevant content\n",
    "    Stick it all in a dictionary\n",
    "    \"\"\"\n",
    "    # Look between the first and second \"---\" in the file\n",
    "    metadata = md_file.split(\"---\")[1]\n",
    "    # Split the metadata into a list of lines\n",
    "    metadata = metadata.split(\"\\n\")\n",
    "    # Remove the first and last lines as they are empty\n",
    "    metadata = metadata[1:-1]\n",
    "    #print(metadata)\n",
    "    # Create a dictionary to store the metadata\n",
    "    metadata_dict = {}\n",
    "    # Iterate through the metadata lines\n",
    "    for line in metadata:\n",
    "        # Split the line into key and value\n",
    "        key, value = line.split(\": \")\n",
    "        # Store the key and value in the dictionary\n",
    "        metadata_dict[key] = value\n",
    "        # Reformat the 'date' value to be a datetime object\n",
    "        if key == \"date\":\n",
    "            value = value.replace(\"1st\", \"1\").replace(\"2nd\", \"2\").replace(\"3rd\", \"3\").replace(\"th\", \"\").replace(\"Jan \", \"January \").replace(\"Feb \", \"February \").replace(\"Mar \", \"March \").replace(\"Apr \", \"April \").replace(\"May \", \"May \").replace(\"Jun \", \"June \").replace(\"Jul \", \"July \").replace(\"Aug \", \"August \").replace(\"Sep \", \"September \").replace(\"Oct \", \"October \").replace(\"Nov \", \"November \").replace(\"Dec \", \"December \")\n",
    "            # metadata_dict[key] = datetime.strptime(value, \"%B %d, %Y\")\n",
    "            # metadata_dict[key] = datetime.strptime(value, \"%d %B %Y\")\n",
    "        if key == \"tags\":\n",
    "            metadata_dict[key] = value.split(\", \")\n",
    "    \n",
    "\n",
    "    \n",
    "    # Look for the first \"#\" in the file\n",
    "    title = md_file.split(\"#\")[1]\n",
    "    #print(title)\n",
    "    # Need to account for when there isn't links, but basically want an if statement here\n",
    "    if \"[\" in title:\n",
    "        # Split the title into a list of lines\n",
    "        title = title.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        # Remove the link in brackets at the end of the title\n",
    "        #print(title)\n",
    "        title = title.split(\"(\")[0]\n",
    "    else:\n",
    "        title = title \n",
    "        \n",
    "    #print(\"Title:\", title)\n",
    "    metadata_dict[\"title\"] = title\n",
    "\n",
    "    # Relevant lines are the ones with text, not the intro bit and not the list of attendees\n",
    "    relevant_lines = md_file.split(\"```\")[2]\n",
    "    relevant_lines = relevant_lines.split(\"---\")[0]\n",
    "    relevant_lines = relevant_lines.split(\"<!--Please don't edit the info panel below-->\")[0]\n",
    "    #print(relevant_lines) \n",
    "\n",
    "    # Look for all the lines starting with # and split them into a list\n",
    "    linebyline = relevant_lines.split(\"\\n\")\n",
    "    hashlines = [line for line in linebyline if line.startswith(\"#\")]\n",
    "    # Remove any leading \"#\" and whitespace\n",
    "    hashlines = [line.lstrip(\"#\").strip() for line in hashlines]\n",
    "    #print(hashlines)\n",
    "    metadata_dict[\"questions\"] = hashlines\n",
    "\n",
    "    content = relevant_lines.split(\"\\n\\n\")\n",
    "    content = [line.replace('\\n',' ').lstrip(\"#\") for line in content]\n",
    "    # Remove any of the authors or editors:\n",
    "    \n",
    "    # Remove urls from the content. Links look like a phrase [link](url). I just want \"link\"\n",
    "    content = [line.split(\"[\")[0] for line in content]\n",
    "    metadata_dict[\"content\"] = content\n",
    "    # print(content)\n",
    "    # print(metadata_dict)\n",
    "    return metadata_dict\n",
    "    \n",
    "example = file_processor(doc_list[5])\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bropenscience is broken science to 1.json\n",
      "Saved  Dataism Is Our New God to 2.json\n",
      "Saved  UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape to 3.json\n",
      "Saved  We created poverty. Algorithms won't make that go away to 4.json\n",
      "Saved  Critical perspectives on Computer Vision to 5.json\n",
      "Saved  'Living in the Hidden Realms of AI: The Workers Perspective' to 6.json\n",
      "Saved The mathematics of crime and terrorism to 7.json\n",
      "Saved  The Rise of Private Spies to 8.json\n",
      "Saved  What an ancient lake in Nevada reveals about the future of tech to 9.json\n",
      "Saved  “Participant” Perceptions of Twitter Research Ethics to 10.json\n",
      "Saved  ESR: Ethics and Society Review of Artificial Intelligence Research to 11.json\n",
      "Saved  Structural Injustice and Individual Responsibility to 12.json\n",
      "Saved  Towards decolonising computational sciences  to 13.json\n",
      "Saved  UK National AI Strategy: Pillar 3 - Governing AI Effectively to 14.json\n",
      "Saved  Statistics, Eugenics and Me to 15.json\n",
      "Saved  A Question of Trust to 16.json\n",
      "Saved  Data Ethics Club's Resolutions 2022\n",
      "\n",
      "<!--Please don't edit the info panel below-->\n",
      "\n",
      "```{admonition} What's this? \n",
      "This is summary of Wednesday 5th January's Data Ethics Club discussion, where we discussed our Data Ethics related New Year's resolution for 2022.\n",
      "\n",
      "The summary was written by Huw Day, who tried to synthesise everyone's contributions to this document and the discussion. \"We\" = \"someone at Data Ethics Club\". \n",
      "Nina Di Cara and Natalie Thurlby helped with the final edit.\n",
      "\n",
      "```\n",
      "\n",
      " to 17.json\n",
      "Saved  Which Programming Languages Use the Least Electricity? to 18.json\n",
      "Saved  “You Social Scientists Love Mind Games”: Experimenting in the “divide” between data science and critical algorithm studies to 19.json\n",
      "Saved  AI in Warfare to 20.json\n",
      "Saved  Data Ethics Club: The Tyranny of Structurelessness to 21.json\n",
      "Saved  The Algorithmic Colonization of Africa to 22.json\n",
      "Saved  Economies of Virtue: The Circulation of ‘Ethics’ in Big Tech to 23.json\n",
      "Saved  Why data is never raw to 24.json\n",
      "Saved  Data Ethics Club: Participatory Data Stewardship to 25.json\n",
      "Saved  JGI Data Week 2022: Automating Inequality to 26.json\n",
      "Saved  Hacking the cis-tem to 27.json\n",
      "Saved  The Failures of Algorithmic Fairness to 28.json\n",
      "Saved  Patient and public involvement to build trust in artificial intelligence: A framework, tools, and case studies to 29.json\n",
      "Saved  ‘The data was there – so why did it take coronavirus to wake us up to racial health inequalities?’ to 30.json\n",
      "Saved  The Ethics of AI generated art to 31.json\n",
      "Saved  Defective Altruism to 32.json\n",
      "Saved  Data Ethics Club's Data Ethics Resolutions 2023\n",
      "\n",
      "```{admonition} What's this? \n",
      "This is summary of Wednesday 25th January's Data Ethics Club discussion, where we discussed our Data Ethics related New Year's resolution for 2023.\n",
      "\n",
      "The summary was written by Huw Day, who tried to synthesise everyone's contributions to this document and the discussion. \"We\" = \"someone at Data Ethics Club\". \n",
      "Nina Di Cara and Natalie Thurlby helped with the final edit.\n",
      "\n",
      "```\n",
      "\n",
      " to 33.json\n",
      "Saved  Data Ethics Club: ChatGPT listed as an author on research papers: many scientists disapprove to 34.json\n",
      "Saved  Limits and Possibilities for “Ethical AI” in Open Source: A Study of Deepfakes to 35.json\n",
      "Saved  Data Ethics Club: The Tech We Won't Build to 36.json\n",
      "Saved  Social Biases in NLP Models as Barriers for Persons with Disabilities to 37.json\n",
      "Saved  Queer In AI: A Case Study in Community-Led Participatory AI to 38.json\n",
      "Saved  Designing Accountable Systems to 39.json\n",
      "Saved  Owen Jones on the classification of abuse online to 40.json\n",
      "Saved  Data Week 2023 Special The Real Danger of ChatGPT to 41.json\n",
      "Saved  Is retail the next sector to be hit by a privacy scandal? to 42.json\n",
      "Saved  Sharing childrens' data online to 43.json\n",
      "Saved  Dimensions of Data Labor to 44.json\n",
      "Saved  Data Ethics Checklist at Seattle Children's Hospital to 45.json\n",
      "Saved  Anatomy of an AI-Powered Malicious Social Botnet to 46.json\n",
      "Saved  Data Ethics Club's New Year's Resolutions 2024\n",
      "\n",
      "```{admonition} What's this? \n",
      "This is a summary of Wednesday 17th January's Data Ethics Club discussion. For our first meeting of the year we usually think about what our resolutions are going to be for the year ahead, and how we could try to achieve them. Those of us that came last year can check back to see if we managed to achieve the resolutions we made then to 47.json\n",
      "Saved  Duolingo cuts workers as it relies more on AI to 48.json\n",
      "Saved  Valentines Day Special - The Ethics of Chatbots to 49.json\n",
      "Saved  Data Ethics Club: Google Search Really Has Gotten Worse, Researchers Find to 50.json\n",
      "Saved  Values in AI Image Systems\n",
      "```{admonition} What's this? \n",
      "This is summary of Wednesday 13th March's Data Ethics Club discussion. This week at Data Ethics Club we used two recent controversies to explore how values are embedded in the creation of new or alternative realities in AI image generation. The first controversy is an AI app called DignifAI that adds clothes to women’s bodies, written about in an article by Catherine Shuttleworth to 51.json\n",
      "Saved  Decolonial AI to 52.json\n",
      "Saved  Artificial Intelligence Act - MEPs adopt landmark law\n",
      "\n",
      "```{admonition} What's this? \n",
      "This is summary of Wednesday 24th April’s Data Ethics Club discussion, where we spoke and wrote about the Artificial Intelligence Act: MEPs adopt landmark law to 53.json\n",
      "Saved  Data Ethics Club: Amazon’s Just Walk Out technology relies on hundreds of workers in India watching you shop to 54.json\n",
      "Saved  Data Ethics Club: The Myers-Briggs Test Has Been Debunked Time and Again. Why Do Companies Still Use It? to 55.json\n",
      "Saved  Data Ethics Club: How AI could save or destroy education to 56.json\n",
      "Saved  Data Ethics Club reads \"Data Feminism\": Summer Bookclub 2024\n",
      "\n",
      "```{admonition} What's this? \n",
      "This is summary of the discussions from Data Feminism Book Club, where we spoke\n",
      "and wrote about Data Feminism to 57.json\n",
      "Saved  Data Ethics Club: ChatGPT is Bullsh*t to 58.json\n",
      "Saved  Data Ethics Club: Time to reality check the promises of machine learning-powered precision medicine to 59.json\n",
      "Saved  Data Ethics Club: Transparent communication of evidence does not undermine public trust in evidence to 60.json\n",
      "Saved  Data Ethics Club Social Special: Data Ethics Club: Creating a collaborative space to discuss data ethics to 61.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "# Make a pandas dataframe for all the writeups\n",
    "# Columns: index number, title, date, author, category, tags, questions\n",
    "import pandas as pd\n",
    "MetaDF = pd.DataFrame(columns = example.keys())\n",
    "\n",
    "# if there isn't a folder called writeups, make one\n",
    "# if there is, save the dictionaries to \n",
    "if not os.path.exists('writeups'):\n",
    "    os.makedirs('writeups')\n",
    "\n",
    "index = 1\n",
    "for doc in doc_list:\n",
    "    dict = file_processor(doc)\n",
    "    if index == 1:\n",
    "        dict['title'] = \"bropenscience is broken science\"\n",
    "    MetaDF = pd.concat([MetaDF, pd.DataFrame([dict])], ignore_index=True)\n",
    "    # Save the dict to a json file\n",
    "    with open(f\"writeups/Writeup{index}.json\", \"w\") as f:\n",
    "        json.dump(dict, f)\n",
    "    print(f\"Saved {dict['title']} to {index}.json\")\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 3, 7, 0, 0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def string_to_datetime(date_string):\n",
    "    \"\"\"\n",
    "    Convert a string to a datetime object\n",
    "    \"\"\"\n",
    "    date_string = date_string.replace(\"1st\", \"1\").replace(\"2nd\", \"2\").replace(\"3rd\", \"3\").replace(\"4th\", \"4\").replace(\"5th\", \"5\").replace(\"6th\", \"6\").replace(\"7th\", \"7\").replace(\"8th\", \"8\").replace(\"9th\", \"9\").replace(\"th\", \"\").replace(\"Jan \", \"January \").replace(\"Feb \", \"February \").replace(\"Mar \", \"March \").replace(\"Apr \", \"April \").replace(\"May \", \"May \").replace(\"Jun \", \"June \").replace(\"Jul \", \"July \").replace(\"Aug \", \"August \").replace(\"Sep \", \"September \").replace(\"Oct \", \"October \").replace(\"Nov \", \"November \").replace(\"Dec \", \"December \")\n",
    "    return datetime.strptime(date_string, \"%B %d, %Y\")\n",
    "string_to_datetime(\"Mar 7th, 2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blogpost</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>questions</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>March 17, 2021</td>\n",
       "      <td>Natalie Zelenka</td>\n",
       "      <td>Write Up</td>\n",
       "      <td>[open science]</td>\n",
       "      <td>bropenscience is broken science</td>\n",
       "      <td>[We know the bro, It's bros all the way down, ...</td>\n",
       "      <td>2021-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>March 31, 2021</td>\n",
       "      <td>Nina Di Cara</td>\n",
       "      <td>Write Up</td>\n",
       "      <td>[philosophy, AGI]</td>\n",
       "      <td>Dataism Is Our New God</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true</td>\n",
       "      <td>April 14, 2021</td>\n",
       "      <td>Nina Di Cara, Natalie Zelenka</td>\n",
       "      <td>Write Up</td>\n",
       "      <td>[policy, oversight ]</td>\n",
       "      <td>UK Statistics Authority: Identifying gaps, op...</td>\n",
       "      <td>[General feedback, Notes on Annex B, Addional ...</td>\n",
       "      <td>2021-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true</td>\n",
       "      <td>April 28, 2021</td>\n",
       "      <td>Huw Day</td>\n",
       "      <td>Write Up</td>\n",
       "      <td>[bias, prediction, structural injustice]</td>\n",
       "      <td>We created poverty. Algorithms won't make tha...</td>\n",
       "      <td>[Summary, Intro, How deserving of help are we?...</td>\n",
       "      <td>2021-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>May 12, 2021</td>\n",
       "      <td>Huw Day</td>\n",
       "      <td>Write Up</td>\n",
       "      <td>[standpoint theory]</td>\n",
       "      <td>Critical perspectives on Computer Vision</td>\n",
       "      <td>[The View from Nowhere, Better accounting for ...</td>\n",
       "      <td>2021-05-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  blogpost            date                         author  category  \\\n",
       "0     true  March 17, 2021                Natalie Zelenka  Write Up   \n",
       "1     true  March 31, 2021                   Nina Di Cara  Write Up   \n",
       "2     true  April 14, 2021  Nina Di Cara, Natalie Zelenka  Write Up   \n",
       "3     true  April 28, 2021                        Huw Day  Write Up   \n",
       "4     true    May 12, 2021                        Huw Day  Write Up   \n",
       "\n",
       "                                       tags  \\\n",
       "0                            [open science]   \n",
       "1                         [philosophy, AGI]   \n",
       "2                      [policy, oversight ]   \n",
       "3  [bias, prediction, structural injustice]   \n",
       "4                       [standpoint theory]   \n",
       "\n",
       "                                               title  \\\n",
       "0                    bropenscience is broken science   \n",
       "1                             Dataism Is Our New God   \n",
       "2   UK Statistics Authority: Identifying gaps, op...   \n",
       "3   We created poverty. Algorithms won't make tha...   \n",
       "4           Critical perspectives on Computer Vision   \n",
       "\n",
       "                                           questions   DateTime  \n",
       "0  [We know the bro, It's bros all the way down, ... 2021-03-17  \n",
       "1                                                 [] 2021-03-31  \n",
       "2  [General feedback, Notes on Annex B, Addional ... 2021-04-14  \n",
       "3  [Summary, Intro, How deserving of help are we?... 2021-04-28  \n",
       "4  [The View from Nowhere, Better accounting for ... 2021-05-12  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetaDF.drop(\"content\", axis=1, inplace=True)\n",
    "# Turn the \"date\" column into a datetime object\n",
    "MetaDF[\"DateTime\"] = MetaDF[\"date\"].apply(string_to_datetime)\n",
    "MetaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('documents'):\n",
    "    os.makedirs('documents')\n",
    "MetaDF.to_csv(\"documents/Writeups.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
